{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x-1iECAJOEy-VU42zxWM0rxwsGLqJBeQ",
      "authorship_tag": "ABX9TyOD+E/vGAR+TLsqlDSIgcai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillyKitheka/code-doyen/blob/main/betika_PDF_convert_to_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w291ocIZMbe",
        "outputId": "9d91a266-2002-4c8f-a390-b51bff84922c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cux0xNVUlfb"
      },
      "outputs": [],
      "source": [
        "# This function is of VITAL IMPORTANCE to the project. It is used to convert pdf files to csv\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import codecs\n",
        "import PyPDF2\n",
        "\n",
        "def convert_pdf_to_csv(folder_path):\n",
        "\n",
        "  # iterate through the files in the folder\n",
        "  for filename in os.listdir(folder_path):\n",
        "\n",
        "    #check if the file is a pdf file\n",
        "      if filename.endswith('.pdf'):\n",
        "\n",
        "        # open the pdf file\n",
        "                    f = open(os.path.join(folder_path, filename), 'rb')\n",
        "\n",
        "            #read the pdf file\n",
        "                    pdf = PyPDF2.PdfReader(f)\n",
        "\n",
        "            # get the number of pages in the pdf file\n",
        "                    num_pages = len(pdf.pages)\n",
        "\n",
        "            # initialize an empty list\n",
        "                    data = []\n",
        "\n",
        "            # loop through the pages in the pdf file\n",
        "                    for i in range(num_pages):\n",
        "                      # read the page\n",
        "                              page = pdf.pages[i]\n",
        "                              text = page.extract_text()\n",
        "\n",
        "                      # extract the text from the page\n",
        "                              text = text.strip()\n",
        "\n",
        "                      # split the text into lines\n",
        "                              lines = text.split('\\n')\n",
        "                      \n",
        "                      # append the lines to the list\n",
        "                              data.extend(lines)\n",
        "\n",
        "                      # convert the data list to a csv string\n",
        "                              csv_data = '\\n'.join(data)\n",
        "\n",
        "                      # write the csv string to a csv file\n",
        "                              csv_filename = filename[:-4] + '.csv'\n",
        "                              with codecs.open(os.path.join(folder_path, csv_filename), 'w', encoding = 'utf-8') as csv_f:\n",
        "                                      csv_f.write(csv_data)\n",
        "\n",
        "                                      # close the pdf file\n",
        "                              f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_pdf_to_csv('/content/drive/MyDrive/unprocessed_collection')"
      ],
      "metadata": {
        "id": "m8bu-QFTZfmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py==2.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "kUSkAqxG5ql1",
        "outputId": "777e397e-81f0-4b9b-a619-611a8ecc15cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tabula-py==2.3.0\n",
            "  Downloading tabula_py-2.3.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro in /usr/local/lib/python3.9/dist-packages (from tabula-py==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.9/dist-packages (from tabula-py==2.3.0) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tabula-py==2.3.0) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.3->tabula-py==2.3.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.3->tabula-py==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py==2.3.0) (1.16.0)\n",
            "Installing collected packages: tabula-py\n",
            "  Attempting uninstall: tabula-py\n",
            "    Found existing installation: tabula-py 2.7.0\n",
            "    Uninstalling tabula-py-2.7.0:\n",
            "      Successfully uninstalled tabula-py-2.7.0\n",
            "Successfully installed tabula-py-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tabula"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tabula\n",
        "\n",
        "def extract_tables_from_pdfs(folder_path):\n",
        "    # Iterate over files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        # Check if the file is a PDF\n",
        "        if file_name.lower().endswith('.pdf'):\n",
        "            # Create the file path by joining the folder path and file name\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            \n",
        "            # Specify the output file path for the CSV file\n",
        "            output_file_path = os.path.splitext(file_path)[0] + '.csv'\n",
        "            \n",
        "            # Extract tables from the PDF file and save as CSV\n",
        "            try:\n",
        "                df = tabula.read_pdf(file_path, pages='1', multiple_tables=True)[0]\n",
        "                df.to_csv(output_file_path, index=False)\n",
        "                print(f'Table extracted from {file_name} and saved as {output_file_path}')\n",
        "            except Exception as e:\n",
        "                print(f'Error extracting table from {file_name}: {e}')\n",
        "\n",
        "# Example usage:            \n",
        "folder_path = '/content/drive/MyDrive/unprocessed_collection'  # Update with your actual folder path\n",
        "extract_tables_from_pdfs(folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhOBp3aB5Nam",
        "outputId": "dec7b44d-7549-4d6c-c46e-0ed778feb933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table extracted from mid_weekjp_14-02-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_14-02-2023.csv\n",
            "Table extracted from mid_weekjp_25-03-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_25-03-2023.csv\n",
            "Table extracted from mid_weekjp_18-03-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_18-03-2023.csv\n",
            "Table extracted from mid_weekjp_11-03-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_11-03-2023.csv\n",
            "Table extracted from mid_weekjp_21-02-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_21-02-2023.csv\n",
            "Table extracted from mid_weekjp_04-03-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_04-03-2023.csv\n",
            "Table extracted from mid_weekjp_01-04-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_01-04-2023.csv\n",
            "Table extracted from mid_weekjp_25-03-2023_REAL.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_25-03-2023_REAL.csv\n",
            "Table extracted from mid_weekjp_09-04-2023.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_09-04-2023.csv\n",
            "Table extracted from mid_weekjp_16-04-2023_prediction_Set.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_16-04-2023_prediction_Set.csv\n",
            "Table extracted from mid_weekjp_15-04-2023_prediction_Set.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_15-04-2023_prediction_Set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwx1KS_1RBtI",
        "outputId": "a2c19071-61d7-441a-d4e2-98118c49c180"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.7.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distro\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tabula-py) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.9/dist-packages (from tabula-py) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.3->tabula-py) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Installing collected packages: distro, tabula-py\n",
            "Successfully installed distro-1.8.0 tabula-py-2.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#THIS FUNCTION WORKED VERY WELL to convert a single pdf file to csv! I like it!\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import tabula\n",
        "\n",
        "def extract_table_from_pdf(pdf_file_path):\n",
        "    \"\"\"\n",
        "    Extracts tables from a PDF file and saves them as CSV files.\n",
        "    \n",
        "    Args:\n",
        "        pdf_file_path (str): File path to the PDF file\n",
        "        \n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Open the PDF file\n",
        "    with open(pdf_file_path, 'rb') as file:\n",
        "        # Create a PdfReader object\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        \n",
        "        # Extract the number of pages in the PDF file\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "        \n",
        "        # Initialize a list to store extracted tables\n",
        "        extracted_tables = []\n",
        "        \n",
        "        # Iterate through each page in the PDF file\n",
        "        for i in range(num_pages):\n",
        "            # Extract the table from the current page\n",
        "            df = tabula.read_pdf(pdf_file_path, pages=i+1)[0]\n",
        "            \n",
        "            # If a table is found, append it to the list of extracted tables\n",
        "            if df is not None:\n",
        "                extracted_tables.append(df)\n",
        "        \n",
        "        # If no tables are found, raise an exception\n",
        "        if not extracted_tables:\n",
        "            raise Exception(\"No tables found in the PDF file.\")\n",
        "        \n",
        "        # Concatenate all extracted tables into a single DataFrame\n",
        "        combined_df = pd.concat(extracted_tables, ignore_index=True)\n",
        "        \n",
        "        # Generate a CSV file name based on the input PDF file name\n",
        "        csv_file_name = os.path.splitext(os.path.basename(pdf_file_path))[0] + \".csv\"\n",
        "        \n",
        "        # Get the directory path of the input PDF file\n",
        "        pdf_directory = os.path.dirname(pdf_file_path)\n",
        "        \n",
        "        # Construct the full file path for the CSV file in the same directory as the PDF file\n",
        "        csv_file_path = os.path.join(pdf_directory, csv_file_name)\n",
        "        \n",
        "        # Save the combined DataFrame as a CSV file in the same directory as the input PDF file\n",
        "        combined_df.to_csv(csv_file_path, index=False)\n",
        "        \n",
        "        print(f\"Tables extracted from {pdf_file_path} and saved as {csv_file_path}.\")\n"
      ],
      "metadata": {
        "id": "UaVM-XYQTqb7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "extract_table_from_pdf('/content/drive/MyDrive/unprocessed_collection/mid_weekjp_23-04-2023_current_prediction_set.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-FcVx0ETu3I",
        "outputId": "e44c42f7-c5c3-4555-8344-22b448684ba7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables extracted from /content/drive/MyDrive/unprocessed_collection/mid_weekjp_23-04-2023_current_prediction_set.pdf and saved as /content/drive/MyDrive/unprocessed_collection/mid_weekjp_23-04-2023_current_prediction_set.csv.\n"
          ]
        }
      ]
    }
  ]
}